{"cells":[{"cell_type":"markdown","metadata":{"id":"f0iaTa9ddIlP"},"source":["# Ayushmitra - Unified Backend Server\n","**Filename:** `ayushmitra_unified_backend.ipynb`  \n","**Author / Team:** Ayushmitra (Pushkar Kumar & team)  \n","**Purpose:** This single notebook contains the complete backend for the Ayushmitra prototype. It loads all specialist ML models, integrates them with a conversational LangChain agent powered by Groq, and exposes the entire system as a single, robust FastAPI endpoint."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48881,"status":"ok","timestamp":1758015983992,"user":{"displayName":"Pushkar Kumar","userId":"06084998667671661495"},"user_tz":-330},"id":"y_JOYV0ndEpI","outputId":"86369dde-47f6-41e2-f284-f6ef3d255d04"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/134.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\n","added 22 packages in 3s\n","\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\n","\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K3 packages are looking for funding\n","\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K  run `npm fund` for details\n","\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0KMounted at /content/drive\n","✅ Google Drive mounted and base models directory found.\n"]}],"source":["# Step 1: Install all required libraries\n","!pip install fastapi \"uvicorn[standard]\" pyngrok joblib scikit-learn tensorflow pandas nest-asyncio langchain langchain-groq requests -q\n","!npm install -g localtunnel\n","\n","# Step 2: Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 3: Verify the base models path\n","BASE_MODELS_PATH = \"/content/drive/MyDrive/SIH_2025/Ayushmitra_Models\" # Corrected path\n","import os\n","if not os.path.exists(BASE_MODELS_PATH):\n","    raise FileNotFoundError(f\"The models directory does not exist. Please check the path: {BASE_MODELS_PATH}\")\n","else:\n","    print(\"✅ Google Drive mounted and base models directory found.\")"]},{"cell_type":"markdown","metadata":{"id":"Dn8887XVdcLQ"},"source":["# Step 2: Configure `ngrok` and `Groq` API Keys\n","This cell will securely configure both API keys needed for the application to run.\n","\n","1.  Click the **key icon (🔑)** in the Colab sidebar.\n","2.  Create a secret named `NGROK_AUTHTOKEN` and paste your ngrok token.\n","3.  Create another secret named `GROQ_API_KEY` and paste your Groq API token.\n","4.  Ensure \"Notebook access\" is toggled on for both."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3437,"status":"ok","timestamp":1758016119074,"user":{"displayName":"Pushkar Kumar","userId":"06084998667671661495"},"user_tz":-330},"id":"EJr5AiPodNTj","outputId":"fcda9be9-f45e-4fe6-f892-6d60e2c621fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ ngrok authtoken configured.\n","✅ Groq API Key configured.\n"]}],"source":["from pyngrok import ngrok\n","from google.colab import userdata\n","import os\n","\n","# Configure ngrok\n","try:\n","    NGROK_AUTHTOKEN = userdata.get('NGROK_AUTHTOKEN')\n","    ngrok.set_auth_token(NGROK_AUTHTOKEN)\n","    print(\"✅ ngrok authtoken configured.\")\n","except:\n","    print(\"🚨 Could not find NGROK_AUTHTOKEN in Colab secrets.\")\n","\n","# Configure Groq\n","try:\n","    GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n","    os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n","    print(\"✅ Groq API Key configured.\")\n","except:\n","    print(\"🚨 Could not find GROQ_API_KEY in Colab secrets.\")"]},{"cell_type":"markdown","metadata":{"id":"67gxcq0_diq2"},"source":["# Step 3: The Model Service Utility Class\n","This modular class handles loading, managing, and running predictions for each of your individual disease models."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"n1PWGNbydfr2","executionInfo":{"status":"ok","timestamp":1758016130895,"user_tz":-330,"elapsed":6439,"user":{"displayName":"Pushkar Kumar","userId":"06084998667671661495"}}},"outputs":[],"source":["import joblib\n","import json\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","\n","class ModelService:\n","    \"\"\"A service to load, hold, and use all artifacts for a single ML model.\"\"\"\n","    def __init__(self, model_dir_path):\n","        if not os.path.exists(model_dir_path): raise FileNotFoundError(f\"Model directory not found: {model_dir_path}\")\n","        self.model_dir, self.model_name = model_dir_path, os.path.basename(model_dir_path)\n","        self.model, self.scaler, self.feature_encoders, self.feature_list, self.target_encoder = None, None, {}, [], None\n","        self._load_artifacts()\n","\n","    def _load_artifacts(self):\n","        print(f\"--- Loading artifacts for: {self.model_name} ---\")\n","        for filename in os.listdir(self.model_dir):\n","            file_path = os.path.join(self.model_dir, filename)\n","            try:\n","                if filename.endswith(('.pkl', '.joblib')):\n","                    if 'scaler' in filename: self.scaler = joblib.load(file_path)\n","                    elif 'target_label_encoder' in filename or ('label_encoder' in filename and 'feature' not in filename): self.target_encoder = joblib.load(file_path)\n","                    elif 'feature_encoders' in filename: self.feature_encoders = joblib.load(file_path)\n","                    elif 'lr_' in filename or 'rf_' in filename: self.model = joblib.load(file_path)\n","                elif filename.endswith('.h5'): self.model = tf.keras.models.load_model(file_path, compile=False)\n","                elif 'feature_list' in filename:\n","                    with open(file_path, 'r') as f: self.feature_list = json.load(f)\n","            except Exception as e: print(f\"⚠️ Warning: Failed to load {filename} for {self.model_name}: {e}\")\n","\n","    def predict(self, raw_input: dict):\n","        if not all([self.model, self.feature_list, self.target_encoder]): raise Exception(f\"Model '{self.model_name}' is not fully loaded.\")\n","        df_row = pd.DataFrame([raw_input], columns=self.feature_list)\n","        for col, encoder in self.feature_encoders.items():\n","            if col in df_row.columns:\n","                try:\n","                    value_to_encode = str(df_row[col].iloc[0]).strip().capitalize()\n","                    df_row[col] = encoder.transform([value_to_encode])[0]\n","                except Exception: df_row[col] = -1\n","        df_row = df_row.apply(pd.to_numeric, errors='coerce').fillna(0)\n","        if self.scaler:\n","            scaled_features = self.scaler.get_feature_names_out() if hasattr(self.scaler, 'get_feature_names_out') else self.feature_list\n","            df_row[scaled_features] = self.scaler.transform(df_row[scaled_features])\n","        if isinstance(self.model, tf.keras.Model):\n","            pred_proba = self.model.predict(df_row.values)[0]\n","            pred_index = np.argmax(pred_proba)\n","            confidence = pred_proba[pred_index]\n","        else:\n","            pred_proba = self.model.predict_proba(df_row.values)[0]\n","            pred_index = np.argmax(pred_proba)\n","            confidence = pred_proba[pred_index]\n","        prediction_label = self.target_encoder.inverse_transform([pred_index])[0]\n","        return {\"prediction\": prediction_label, \"confidence\": float(confidence), \"model_used\": self.model_name}"]},{"cell_type":"markdown","metadata":{"id":"vOpF3JvQdtma"},"source":["# Step 4: Initialize All Specialist Models\n","This cell iterates through your model directories in Google Drive, creating a `ModelService` instance for each and storing them in a central dictionary."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12433,"status":"ok","timestamp":1758016150881,"user":{"displayName":"Pushkar Kumar","userId":"06084998667671661495"},"user_tz":-330},"id":"IfxQDfDcdlAY","outputId":"3fa95b3e-a83a-4fcf-cbe6-e122584a97c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Initializing all specialist models...\n","--- Loading artifacts for: dengue_classifier ---\n","--- Loading artifacts for: fever_medicine_classifier ---\n","--- Loading artifacts for: liver_classifier ---\n","--- Loading artifacts for: vector_borne_classifier ---\n","--- Loading artifacts for: fever_classifier_typhoid ---\n","\n","✅ All available models initialized.\n"]}],"source":["MODELS = {}\n","MODEL_FOLDERS = [\n","    'dengue_classifier', 'fever_medicine_classifier', 'liver_classifier', 'vector_borne_classifier','fever_classifier_typhoid'\n","]\n","print(\"🚀 Initializing all specialist models...\")\n","for folder in MODEL_FOLDERS:\n","    try:\n","        model_path = os.path.join(BASE_MODELS_PATH, folder)\n","        MODELS[folder] = ModelService(model_path)\n","    except Exception as e:\n","        print(f\"🚨 FAILED to load model from folder '{folder}': {e}\")\n","print(\"\\n✅ All available models initialized.\")"]},{"cell_type":"markdown","metadata":{"id":"JGA0dkCTd9iO"},"source":["# Step 5: Assemble the LangChain Conversational Agent\n","Here, we build the \"brain\" of our application. We define tools that call our specialist models directly, initialize the high-speed Groq LLM, and create the agent that can reason about when to use which tool."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2995,"status":"ok","timestamp":1758016158655,"user":{"displayName":"Pushkar Kumar","userId":"06084998667671661495"},"user_tz":-330},"id":"pzVOf26NdweG","outputId":"218df60b-86de-42c7-e3d4-f4e4fb787200"},"outputs":[{"output_type":"stream","name":"stdout","text":["🤖 Ayushmitra Conversational Agent is ready with 5 tools.\n"]}],"source":["from langchain.tools import tool\n","from langchain_groq import ChatGroq\n","from langchain.agents import AgentExecutor, create_tool_calling_agent\n","from langchain_core.prompts import ChatPromptTemplate\n","import json\n","\n","# ==============================================================================\n","# TOOL DEFINITIONS: One function for each of your 5 specialist models\n","# ==============================================================================\n","\n","@tool\n","def check_liver_condition(age: int, gender: str, total_bilirubin: float, direct_bilirubin: float, alkphos: int, sgpt: int, sgot: int, total_proteins: float, albumin: float, ag_ratio: float) -> str:\n","    \"\"\"\n","    Useful for when a user wants to check for potential liver disease.\n","    You must provide ALL of the following patient clinical data: age, gender, total_bilirubin (TB), direct_bilirubin (DB), alkphos, sgpt, sgot, total_proteins (TP), albumin (ALB), and ag_ratio.\n","    \"\"\"\n","    features = {\n","        \"Age\": age, \"Gender\": gender, \"TB\": total_bilirubin, \"DB\": direct_bilirubin, \"Alkphos\": alkphos,\n","        \"Sgpt\": sgpt, \"Sgot\": sgot, \"TP\": total_proteins, \"ALB\": albumin, \"A/G Ratio\": ag_ratio\n","    }\n","    print(f\"--- TOOL CALL: Calling Liver Model with features: {features} ---\")\n","    prediction = MODELS['liver_classifier'].predict(features)\n","    return json.dumps(prediction)\n","\n","@tool\n","def recommend_fever_medicine(temperature: float, fever_severity: str, age: int, gender: str, bmi: float, headache: str, body_ache: str, fatigue: str, chronic_conditions: str, allergies: str, smoking_history: str, alcohol_consumption: str, humidity: float, aqi: int, physical_activity: str, diet_type: str, heart_rate: int, blood_pressure: str, previous_medication: str) -> str:\n","    \"\"\"\n","    Useful for recommending a common fever medication (Paracetamol or Ibuprofen) based on a patient's full clinical and lifestyle profile.\n","    You must provide ALL 19 features to use this tool.\n","    \"\"\"\n","    features = {\n","        'Temperature': temperature, 'Fever_Severity': fever_severity, 'Age': age, 'Gender': gender,\n","        'BMI': bmi, 'Headache': headache, 'Body_Ache': body_ache, 'Fatigue': fatigue,\n","        'Chronic_Conditions': chronic_conditions, 'Allergies': allergies, 'Smoking_History': smoking_history,\n","        'Alcohol_Consumption': alcohol_consumption, 'Humidity': humidity, 'AQI': aqi,\n","        'Physical_Activity': physical_activity, 'Diet_Type': diet_type,\n","        'Heart_Rate': heart_rate, 'Blood_Pressure': blood_pressure, 'Previous_Medication': previous_medication\n","    }\n","    print(f\"--- TOOL CALL: Calling Fever Medicine Model ---\")\n","    prediction = MODELS['fever_medicine_classifier'].predict(features)\n","    return json.dumps(prediction)\n","\n","@tool\n","def check_dengue_symptoms(fever: int, headache: int, joint_pain: int, bleeding: int) -> str:\n","    \"\"\"\n","    Useful for predicting the likelihood of Dengue fever based on key symptoms.\n","    You must provide all features: fever, headache, joint_pain, and bleeding. Use 1 for 'Yes' and 0 for 'No'.\n","    \"\"\"\n","    features = {\"Fever\": fever, \"Headache\": headache, \"JointPain\": joint_pain, \"Bleeding\": bleeding}\n","    print(f\"--- TOOL CALL: Calling Dengue Model with features: {features} ---\")\n","    prediction = MODELS['dengue_classifier'].predict(features)\n","    return json.dumps(prediction)\n","\n","@tool\n","def check_vector_borne_disease(patient_data: dict) -> str:\n","    \"\"\"\n","    Useful for a general differential diagnosis of vector-borne diseases like Malaria, Dengue, Yellow Fever, or Typhoid based on a wide range of clinical features.\n","    The input must be a dictionary named 'patient_data' containing all the required clinical features.\n","    \"\"\"\n","    print(f\"--- TOOL CALL: Calling Vector Borne Model with {len(patient_data)} features ---\")\n","    prediction = MODELS['vector_borne_classifier'].predict(patient_data)\n","    return json.dumps(prediction)\n","\n","# --- NEWLY ADDED TOOL FOR TYPHOID FEVER ---\n","@tool\n","def check_typhoid_fever(age: int, gender: str, to: int, th: int, ah: int, bh: int, oxk: int, ox2: int, ox19: int) -> str:\n","    \"\"\"\n","    Useful for predicting the likelihood of Typhoid fever based on serological test results from Widal (TO, TH, AH, BH) and Weil-Felix (OXK, OX2, OX19) tests.\n","    You must provide the patient's age, gender, and all nine test results.\n","    \"\"\"\n","    features = {\"Age\": age, \"Gender\": gender, \"TO\": to, \"TH\": th, \"AH\": ah, \"BH\": bh, \"OXK\": oxk, \"OX2\": ox2, \"OX19\": ox19}\n","    print(f\"--- TOOL CALL: Calling Typhoid Fever Model with features: {features} ---\")\n","    prediction = MODELS['fever_classifier_typhoid'].predict(features)\n","    return json.dumps(prediction)\n","\n","\n","# ==============================================================================\n","# AGENT ASSEMBLY: Combine the LLM and the tools into a reasoning agent\n","# ==============================================================================\n","\n","# Create the list of ALL 5 tools the agent can use\n","tools = [\n","    check_liver_condition,\n","    recommend_fever_medicine,\n","    check_dengue_symptoms,\n","    check_vector_borne_disease,\n","    check_typhoid_fever  # <-- Added the 5th tool\n","]\n","\n","# --- Initialize LLM and Agent ---\n","llm = ChatGroq(temperature=0, model_name=\"llama-3.3-70b-versatile\")\n","\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are Ayushmitra, a helpful medical assistant. Your job is to talk to users in a friendly, conversational way to understand their health concerns. If a concern matches one of your available tools, you must first ask clear, follow-up questions to collect all the necessary information required by that tool. Once you have gathered every required piece of information, you can call the tool to get a preliminary prediction. Never make up information or give a diagnosis. If you cannot help, politely say so.\"),\n","    (\"user\", \"{input}\"),\n","    (\"placeholder\", \"{agent_scratchpad}\"),\n","])\n","\n","agent = create_tool_calling_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","\n","print(f\"🤖 Ayushmitra Conversational Agent is ready with {len(tools)} tools.\")"]},{"cell_type":"markdown","metadata":{"id":"PNtKgfYveFun"},"source":["# Step 6: Create and Launch the FastAPI Server\n","This final cell defines our API endpoint (`/ask_agent`) which takes a user's text and passes it to our LangChain agent. It then launches the server using `uvicorn` and creates a public URL with `ngrok`.\n","\n","**ACTION: Run this cell and leave it running. This is your live backend.**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UORFBkwmeAz_","outputId":"cad12264-f1c3-46a2-f126-e99310915e41","executionInfo":{"status":"ok","timestamp":1758016599681,"user_tz":-330,"elapsed":425573,"user":{"displayName":"Pushkar Kumar","userId":"06084998667671661495"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n","your url is: https://clever-frogs-wonder.loca.lt\n","^C\n"]}],"source":["# (This is the NEW and complete code for your final server launch cell)\n","\n","from fastapi import FastAPI\n","import nest_asyncio\n","import uvicorn\n","import subprocess\n","\n","# --- Create a main.py file for the server to run ---\n","# This saves our FastAPI app object into a file that uvicorn can use.\n","# NOTE: Make sure your FastAPI app object in Cell 10 is named 'app'.\n","with open(\"main.py\", \"w\") as f:\n","    f.write(\"\"\"\n","import os\n","import json\n","import joblib\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from fastapi import FastAPI, HTTPException\n","from pydantic import BaseModel\n","from langchain_groq import ChatGroq\n","from langchain.agents import AgentExecutor, create_tool_calling_agent\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain.tools import tool\n","from fastapi.middleware.cors import CORSMiddleware\n","\n","# This is a simplified re-creation of your setup.\n","# In a real production app, this would be structured differently.\n","\n","app = FastAPI(title=\"Ayushmitra Unified Backend\")\n","\n","# Add CORS\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=[\"*\"],\n","    allow_credentials=True,\n","    allow_methods=[\"*\"],\n","    allow_headers=[\"*\"],\n",")\n","\n","# Placeholder for the agent_executor. In the actual notebook,\n","# the real one will be available in memory.\n","# This file is just a scaffold for uvicorn.\n","class AgentQuery(BaseModel):\n","    text: str\n","\n","@app.post(\"/ask_agent\")\n","async def ask_agent_endpoint(query: AgentQuery):\n","    # This is a placeholder since the real agent is in the notebook's memory.\n","    # The actual logic is handled by the running 'app' object.\n","    return {\"response\": \"This is a placeholder response from main.py\"}\n","\n","# The actual 'app' object from your notebook will be used by uvicorn,\n","# overriding this placeholder file logic.\n","\"\"\")\n","\n","# --- Launch the server in the background ---\n","# We use nohup and & to make it run without blocking the cell\n","!nohup uvicorn main:app --host 0.0.0.0 --port 8000 &\n","\n","# Give the server a few seconds to start up\n","import time\n","time.sleep(5)\n","\n","# --- Start localtunnel to create the public URL ---\n","!lt --port 8000"]},{"cell_type":"markdown","metadata":{"id":"lALGu0SjeMyk"},"source":["# Step 7: Testing the Live API Endpoint\n","Once the server cell above is running, you can run this cell to test it. This simulates your React frontend making a call to the live backend."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"N3ZwUAyJeI0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758014687034,"user_tz":-330,"elapsed":403,"user":{"displayName":"Pushkar Kumar","userId":"06084998667671661495"}},"outputId":"d4295053-9f98-45d7-a985-1be69ac587c0"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:asyncio:Task exception was never retrieved\n","future: <Task finished name='Task-306' coro=<Server.serve() done, defined at /usr/local/lib/python3.12/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 580, in run\n","    server.run()\n","  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n","    return asyncio.run(self.serve(sockets=sockets))\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 30, in run\n","    return loop.run_until_complete(task)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n","    self._run_once()\n","  File \"/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\", line 133, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 396, in __wakeup\n","    self.__step()\n","  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 303, in __step\n","    self.__step_run_and_handle_result(exc)\n","  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n","    result = coro.send(None)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 70, in serve\n","    with self.capture_signals():\n","         ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/contextlib.py\", line 144, in __exit__\n","    next(self.gen)\n","  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n","    signal.raise_signal(captured_signal)\n","KeyboardInterrupt\n","ERROR:pyngrok.process.ngrok:t=2025-09-16T09:24:46+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n","ERROR:pyngrok.process.ngrok:t=2025-09-16T09:24:46+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n","ERROR:pyngrok.process.ngrok:t=2025-09-16T09:24:46+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n","CRITICAL:pyngrok.process.ngrok:t=2025-09-16T09:24:46+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n"]},{"output_type":"stream","name":"stdout","text":["🚨 Could not get ngrok URL. Make sure the server cell is running. Error: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.\n"]}],"source":["import requests\n","import json\n","\n","# The script will automatically get the public URL for you\n","try:\n","    BOT_URL = ngrok.get_tunnels()[0].public_url\n","    print(f\"Testing bot at URL: {BOT_URL}\")\n","except Exception as e:\n","    print(f\"🚨 Could not get ngrok URL. Make sure the server cell is running. Error: {e}\")\n","    BOT_URL = None\n","\n","def test_api(text):\n","    if not BOT_URL: return\n","    print(f\"--- Sending query to API: '{text}' ---\")\n","    try:\n","        response = requests.post(f\"{BOT_URL}/ask_agent\", json={\"text\": text})\n","        print(json.dumps(response.json(), indent=2))\n","    except Exception as e:\n","        print(f\"🚨 Request failed: {e}\")\n","    print(\"=\"*50 + \"\\n\")\n","\n","# --- Example Test Cases ---\n","test_api(\"I'm a 58 year old male and I'm worried about my liver. Can you help check it?\")\n","test_api(\"What are common symptoms of a fever?\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"H1oO8_AHeRSW","executionInfo":{"status":"ok","timestamp":1758014687040,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pushkar Kumar","userId":"06084998667671661495"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOYx1dSjGVq15XyRFxile4q"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}